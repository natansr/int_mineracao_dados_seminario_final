{"cells":[{"cell_type":"markdown","metadata":{"id":"eQY8-mpTPGay"},"source":["# Classificação de documentos para Desambiguação de Nomes de Autores (AND)\n"]},{"cell_type":"markdown","metadata":{"id":"-auut1sCPGaz"},"source":["### Introdução\n","\n","Nesse tutorial vamos fazer o fine-tuning de um modelo transformer (BERT) para **Classificação Multiclasse de documentos**.\n","\n","Vamos utiliza-lo para performar e resolver o problema de Desambiguação de Nomes de Autores (AND) de determinado repositório bibliográfico digital ou dataset.\n","\n","#### Fluxo do Notebook\n","\n","The notebook will be divided into seperate sections to provide a organized walk through for the process used. This process can be modified for individual use cases. The sections are:\n","\n","1. [Importando Bibliotecas Python e preparando o ambiente](#section01)\n","2. [Importando e Pré-processando os dados do domínio](#section02)\n","3. [Preparando o Conjunto de Dados e o Carregador de Dados](#section03)\n","4. [Criando a Rede Neural para Ajuste Fino](#section04)\n","5. [Fine Tuning e ajuste do Modelo](#section05)\n","6. [Validando o Desempenho do Modelo](#section06)\n","7. [Salvando o modelo e artefatos para Inferência Futura](#section07)\n","\n","\n","\n","#### Detalhes técnicos\n","\n","Este script utiliza várias ferramentas projetadas por outras equipes. Detalhes das ferramentas utilizadas abaixo. Certifique-se de que esses elementos estejam presentes em sua configuração para implementar com sucesso este script.\n","\n","\n","Modelo de Linguagem Usado:\n","- O SciBERT é um modelo de linguagem baseado em transformers, desenvolvido especificamente para tarefas relacionadas ao domínio científico. Ele utiliza uma arquitetura semelhante ao BERT, porém pré-treinado em uma grande quantidade de texto científico. Algumas características do SciBERT incluem:\n","- Especialização Científica: O SciBERT é ajustado para entender melhor o vocabulário e a estrutura de documentos científicos, o que o torna mais adequado para tarefas específicas do domínio científico.\n","- Transferência de Aprendizado: Como parte da família BERT, o SciBERT se beneficia da transferência de aprendizado, onde os conhecimentos adquiridos durante o pré-treinamento podem ser aplicados a tarefas específicas, como classificação de texto, extração de informações, entre outras.\n","- Desempenho em Tarefas Científicas: Devido à sua especialização, o SciBERT geralmente supera modelos genéricos em tarefas relacionadas ao domínio científico, proporcionando resultados mais precisos e relevantes.\n","\n","- Recursos adicionais sobre o SciBERT:\n","\t- Postagem no Blog\n","\t- Artigo de Pesquisa\n","\t- Documentação para Python\n","\n","\n","Dados:\n","\n","- Estamos utilizando o conjunto de dados AMiner para desambiguação de nomes, disponível no repositório UCI Machine Learning Repository. Este conjunto de dados é usado para resolver o problema de desambiguação de nomes, onde o mesmo nome pode se referir a diferentes pessoas em diferentes contextos. Os pontos de dados incluem:\n","\t- Nome: Nome da pessoa a ser desambiguada.\n","    - Gênero: Gênero da pessoa (masculino ou feminino).\n","    - Título do Documento: Título do documento em que o nome ocorre.\n","    - Resumo: Resumo do documento.\n","    - Categoria: Categoria do documento.\n","    - ID do Autor: ID do autor associado ao documento.\n","    - Conferência: Nome da conferência em que o documento foi apresentado.\n","    - Ano de Publicação: Ano de publicação do documento.\n","    - Número de citações: Número de citações recebidas pelo documento.\n","\n","- Recursos adicionais sobre o conjunto de dados AMiner para desambiguação de nomes:\n","\t- Artigo de Pesquisa -\n","\n","  Yutao Zhang, Fanjin Zhang, Peiran Yao, and Jie Tang. Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop. In Proceedings of the Twenty-Forth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'18).\n","\n","\t- Documentação - https://github.com/neozhangthe1/disambiguation/\n","  - Download - https://static.aminer.cn/misc/na-data-kdd18.zip\n","\n","\n","\n","\n","Requisitos de Hardware:\n","- Python 3.6 e superior\n","- Pytorch, Transformers e todas as bibliotecas de Machine Learning padrão do Python\n","- Configuração habilitada para GPU\n","\n","Objetivo do Script:\n","- O objetivo deste script é ajustar o SciBERT/BERT para ser capaz de classificar um título e resumos de documentos(publicacões) em classes de autores."]},{"cell_type":"markdown","metadata":{"id":"RZKnYTnCPGa0"},"source":["<a id='section01'></a>\n","### Importando Bibliotecas Python e preparando o ambiente\n","\n","\n","\n","Nesta etapa, vamos importar as bibliotecas e módulos necessários para executar nosso script. As bibliotecas são:\n","* Pandas\n","* Pytorch\n","* Pytorch Utils for Dataset and Dataloader\n","* Transformers\n","* SciBERT Model and Tokenizer\n","\n","Em seguida, vamos preparar o dispositivo para execução do CUDA. Essa configuração é necessária se você quiser aproveitar a GPU embarcada.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuMlXT80GAMK"},"outputs":[],"source":["# Importando as bibliotecas necessárias\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModel, AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQMKTZ4ARk12"},"outputs":[],"source":["# Setting up the device for GPU usage\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zg0APDR1PXO4","executionInfo":{"status":"ok","timestamp":1712368093976,"user_tz":180,"elapsed":462,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}},"outputId":"24ed677c-990d-40c3-f2a7-2b849a05103b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Apr  6 01:48:15 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0              49W / 400W |  19989MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"9xroiVJLPqVI"}},{"cell_type":"markdown","metadata":{"id":"Oi0f9V1rPGa1"},"source":["<a id='section02'></a>\n","### Importando e pré-processando os dados\n","- Os dados estão no Google Drive"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Nome do autor a ser tratado utilizando o SciBert\n","autor = 'hongbin liang'\n","#autor = 'jing luo'\n","#autor = 'wen chang chen'\n","#autor = 'yongsheng zhao'\n","\n","# Definir variável para controlar se deve tratar apenas um autor específico\n","tratar_apenas_um_autor = True\n","\n","# Função para ler o CSV contendo os dados das publicações e autores\n","def read_csv(file_path):\n","    df = pd.read_csv(file_path, delimiter=';')\n","    return df\n","\n","data_dir = \"/content/drive/MyDrive/ADAN/fine_tuning_sci_bert/input\"\n","\n","# Caminho para o arquivo CSV gerado a partir dos JSONs\n","input_csv_file = 'publications_authors.csv'\n","\n","# Importar o CSV para um dataframe do pandas e adicionar os cabeçalhos\n","df = read_csv(os.path.join(data_dir, input_csv_file))\n","\n","if tratar_apenas_um_autor:\n","    # Filtrar apenas as linhas com autor escolhido. e.g, 'hongbin liang'\n","    df_autor = df[df['author_name'] == autor]\n","\n","    # Remover colunas indesejadas e deixar apenas o título da notícia e a categoria que será o alvo\n","    df_autor = df_autor[['publication_title', 'author_id', 'abstract']]\n","\n","    # Criar um dicionário para mapear os IDs dos autores para números inteiros\n","    author_encode_dict = {}\n","\n","    def encode_author(author_id):\n","        if author_id not in author_encode_dict:\n","            author_encode_dict[author_id] = len(author_encode_dict)\n","        return author_encode_dict[author_id]\n","\n","    # Aplicar a codificação aos IDs dos autores\n","    df_autor['ENCODE_AUTHOR'] = df_autor['author_id'].apply(lambda x: encode_author(x))\n","\n","    num_authors = len(author_encode_dict)\n","\n","    classes = num_authors\n","    print(\"Quantidade de classe de autores: \" + str(classes))\n","\n","\n","    # Verificar a saída\n","    df_autor.head()\n","\n","    df = df_autor\n","\n","    # Imprimir a quantidade de documentos para o autor específico\n","    print(\"Quantidade total de documentos: \" + str(df.shape[0]))\n","\n","\n","    df.head()\n","else:\n","    # Remover colunas indesejadas e deixar apenas o título da notícia e a categoria que será o alvo\n","    df_autores = df[['publication_title', 'author_id', 'abstract']]\n","\n","    # Criar um dicionário para mapear os IDs dos autores para números inteiros\n","    author_encode_dict = {}\n","\n","    def encode_author(author_id):\n","        if author_id not in author_encode_dict:\n","            author_encode_dict[author_id] = len(author_encode_dict)\n","        return author_encode_dict[author_id]\n","\n","    # Aplicar a codificação aos IDs dos autores\n","    df_autores['ENCODE_AUTHOR'] = df_autores['author_id'].apply(lambda x: encode_author(x))\n","\n","    num_authors = len(author_encode_dict)\n","\n","    classes = num_authors\n","    print(\"Quantidade de classe de autores: \" + str(classes))\n","\n","\n","\n","\n","    # Verificar a saída\n","    df_autores.head()\n","\n","    df = df_autores\n","\n","    # Imprimir a quantidade de documentos para o autor específico\n","    print(\"Quantidade total de documentos: \" + str(df.shape[0]))\n","\n","    df.head()\n","\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"D1SeZYYDkW14","executionInfo":{"status":"ok","timestamp":1712374274370,"user_tz":180,"elapsed":5985,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}},"outputId":"7b719845-d5ff-40ab-acc0-7f0bbadfdd62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Quantidade de classe de autores: 16\n","Quantidade total de documentos: 198\n"]},{"output_type":"execute_result","data":{"text/plain":["                                   publication_title  \\\n","0  Induced life cycle transition from holocycly t...   \n","1  Impact of alfalfa/cotton intercropping and man...   \n","2  A check-list of the Chinese Megalopodinae (Col...   \n","3  Key to the species of the genus Aristochroa Ts...   \n","4  A review of genus Onycholabis bates (Coleopter...   \n","\n","                  author_id  \\\n","0  5b5433f3e1cd8e4e1516badf   \n","1  5b5433f3e1cd8e4e1516badf   \n","2  5b5433e5e1cd8e4e15f7474c   \n","3  5b5433e5e1cd8e4e15f7474c   \n","4  5b5433e5e1cd8e4e15f7474c   \n","\n","                                            abstract  ENCODE_AUTHOR  \n","0  The Russian wheat aphid (RWA), Diuraphis noxia...              0  \n","1  A short-term study was carried out to evaluate...              0  \n","2  Two genera and 33 taxa of Megalopodinae are re...              1  \n","3  A key to all 14 species of Aristochroa Tschits...              1  \n","4  Species in the genus Onycholabis Bates are bri...              1  "],"text/html":["\n","  <div id=\"df-a8c4767f-b8b6-4a2a-85cb-811806ebf861\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>publication_title</th>\n","      <th>author_id</th>\n","      <th>abstract</th>\n","      <th>ENCODE_AUTHOR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Induced life cycle transition from holocycly t...</td>\n","      <td>5b5433f3e1cd8e4e1516badf</td>\n","      <td>The Russian wheat aphid (RWA), Diuraphis noxia...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Impact of alfalfa/cotton intercropping and man...</td>\n","      <td>5b5433f3e1cd8e4e1516badf</td>\n","      <td>A short-term study was carried out to evaluate...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A check-list of the Chinese Megalopodinae (Col...</td>\n","      <td>5b5433e5e1cd8e4e15f7474c</td>\n","      <td>Two genera and 33 taxa of Megalopodinae are re...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Key to the species of the genus Aristochroa Ts...</td>\n","      <td>5b5433e5e1cd8e4e15f7474c</td>\n","      <td>A key to all 14 species of Aristochroa Tschits...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A review of genus Onycholabis bates (Coleopter...</td>\n","      <td>5b5433e5e1cd8e4e15f7474c</td>\n","      <td>Species in the genus Onycholabis Bates are bri...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8c4767f-b8b6-4a2a-85cb-811806ebf861')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a8c4767f-b8b6-4a2a-85cb-811806ebf861 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a8c4767f-b8b6-4a2a-85cb-811806ebf861');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2b1add05-322d-4cd1-abbd-d14f247dc2a1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b1add05-322d-4cd1-abbd-d14f247dc2a1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2b1add05-322d-4cd1-abbd-d14f247dc2a1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 198,\n  \"fields\": [\n    {\n      \"column\": \"publication_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Luminescence, cathodoluminescence and Ce\",\n          \"A new species of Amara (Coleoptera, Carabidae, Zabrini) from Sichuan Province, China, with additional records for other Amara species from the region\",\n          \"Electronic properties of Ce\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"5b5433f3e1cd8e4e1516badf\",\n          \"5b5433e5e1cd8e4e15f7474c\",\n          \"5b5433f5e1cd8e4e1519f731\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 181,\n        \"samples\": [\n          \"A new subgenus Wraseiellus new subgenus (type species: Pterostichus andrewesi Jedli\\u010dka 1931) of the genus Pterosti-chus from China is described. Eight species and one subspecies are recognized in the new subgenus including three new species and one new subspecies: Pt. (Wraseiellus) comatus new species (Guangxi: Maoershan, N25.87\\u00b0, E110.42\\u00b0), Pt. (Wraseiellus) crassiapex new species (Hubei: Tiechanghuang, N30.75\\u00b0, E110.30\\u00b0), Pt. (Wraseiellus) pseduodiversus new species (Yunnan: Luguhu, N27.63\\u00b0, E100.82\\u00b0), Pt. (Wraseiellus) stictopleurus cangshanensis new subspecies (Yunnan: Cangshan, N25.63\\u00b0, E100.14\\u00b0). Feronia crebrepunctata Straneo, 1937 is newly proposed as junior synonym of Pterosti-chus meyeri Jedli\\u010dka, 1934. A key to all known species and subspecies, images of habitus and genitalia, and distribution maps are provided. Copyright \\u00a9 2013 Magnolia Press.\",\n          \"The phosphors NaGdFPO\",\n          \"Some important aspects of power generation using the co-produced hot oil and water from LB reservoir, Huabei oil field were studied. The temperatures of the formation and the produced liquids were about 120\\u00b0C and 110\\u00b0C respectively. One of the main differences between geothermal and oil wells is the production rate. Usually the production rate in oil wells is much less than that in geothermal wells. The possibility of significantly increasing the total liquid injection and production rates of the injectors and the oil wells in LB reservoir was investigated. Some pilot tests were conducted in the wells. A 400 kW power generator, which was a binary screw expander system, was installed and put into operation after the feasibility and field studies. Operation data over several months since April 2011 were measured and collected.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ENCODE_AUTHOR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":222}]},{"cell_type":"markdown","source":[],"metadata":{"id":"gOZMBJcrqcbM"}},{"cell_type":"markdown","metadata":{"id":"9XZ2KEKXPGa1"},"source":["<a id='section03'></a>\n","### Preparando o Conjunto de Dados e o Carregador de Dados\n","\n","Vamos começar definindo algumas variáveis-chave que serão usadas posteriormente durante o estágio de treinamento/ajuste fino.\n","Seguido pela criação da classe Dataset - Isso define como o texto é pré-processado antes de ser enviado para a rede neural. Também vamos definir o Dataloader que irá alimentar os dados em lotes para a rede neural para treinamento e processamento adequados.\n","Dataset e Dataloader são construções da biblioteca PyTorch para definir e controlar o pré-processamento dos dados e sua passagem para a rede neural. Para ler mais sobre Dataset e Dataloader, consulte a [documentação do PyTorch](https://pytorch.org/docs/stable/data.html).\n","\n","#### Classe *Triage* Dataset\n","- Esta classe é definida para aceitar o DataFrame como entrada e gerar saída tokenizada que é usada pelo modelo SciBERT para treinamento.\n","- Estamos usando o tokenizador SciBERT para tokenizar os dados na coluna `TITLE` e `ABSTRACT` do dataframe.\n","- O tokenizador usa o método `encode_plus` para realizar a tokenização e gerar as saídas necessárias, a saber: `ids`, `attention_mask`.\n","- Para ler mais sobre o tokenizador, [consulte este documento](https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer).\n","- `target` é a categoria codificada no título da notícia.\n","- A classe *Triage* é usada para criar 2 conjuntos de dados, para treinamento e para validação.\n","- O *Conjunto de Dados de Treinamento* é usado para ajustar o modelo: **80% dos dados originais**.\n","- O *Conjunto de Dados de Validação* é usado para avaliar o desempenho do modelo. O modelo não viu esses dados durante o treinamento.\n","\n","#### Dataloader\n","- Dataloader é usado para criar carregadores de dados de treinamento e validação que carregam dados para a rede neural de maneira definida. Isso é necessário porque todos os dados do conjunto de dados não podem ser carregados na memória de uma vez, portanto, a quantidade de dados carregados na memória e depois passados para a rede neural precisa ser controlada.\n","- Esse controle é alcançado usando parâmetros como `batch_size` e `max_len`.\n","- Carregadores de dados de treinamento e validação são usados nas partes de treinamento e validação do fluxo, respectivamente.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrBr2YesGdO_"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# Defining some key variables that will be used later on in the training\n","MAX_LEN = 256  # Defina o comprimento máximo de acordo com os requisitos do modelo SciBERT\n","TRAIN_BATCH_SIZE = 64\n","VALID_BATCH_SIZE = 32\n","EPOCHS = 20\n","#LEARNING_RATE = 1e-04\n","LEARNING_RATE = 2e-05\n","tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class Triage(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        title = str(self.data.publication_title[index])\n","        title = \" \".join(title.split())\n","\n","        abstract = str(self.data.abstract[index])\n","        abstract = \" \".join(abstract.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            abstract,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data.ENCODE_AUTHOR[index], dtype=torch.long)\n","        }\n","\n","    def __len__(self):\n","        num_labels = len(self.data.ENCODE_AUTHOR)\n","        print(\"Número total de documentos:\", num_labels)\n","        return self.len\n","\n","\n","\n","\n"],"metadata":{"id":"0TwXaWH-6lPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zcwq13c0NE9c","outputId":"5bc690d7-1686-42fe-8df5-f953a1acaed3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712374069857,"user_tz":180,"elapsed":511,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (299, 4)\n","TRAIN Dataset: (239, 4)\n","TEST Dataset: (60, 4)\n"]}],"source":["# Creating the dataset and dataloader for the neural network\n","\n","train_size = 0.8\n","train_dataset=df.sample(frac=train_size,random_state=200)\n","test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n","\n","testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1BgA1CkQSYa","executionInfo":{"status":"ok","timestamp":1712374074790,"user_tz":180,"elapsed":440,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fa6789b-6683-4d81-91d2-67c72fd0b2b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Relatório Treinamento\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Relatório Teste\n","Número total de documentos: 60\n","Número total de documentos: 60\n"]}],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","print(\"Relatório Treinamento\")\n","training_loader = DataLoader(training_set, **train_params)\n","print(\"Relatório Teste\")\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"cell_type":"markdown","metadata":{"id":"0vDgNZ8oPGa3"},"source":["<a id='section04'></a>\n","### Criando a Rede Neural para Ajuste Fino\n","\n","#### Rede Neural\n"," - Estaremos criando uma rede neural com a classe `SciBERTClass`.\n"," - Esta rede terá o modelo de linguagem SciBERT, seguido por uma camada `dropout` e finalmente uma camada `Linear` para obter as saídas finais.\n"," - Os dados serão alimentados ao modelo de linguagem SciBERT conforme definido no conjunto de dados.\n"," - As saídas da camada final é o que será comparado com a `categoria codificada` para determinar a precisão das previsões do modelo.\n"," - Iniciaremos uma instância da rede chamada `model`. Esta instância será usada para o treinamento e, em seguida, para salvar o modelo treinado final para inferência futura.\n","\n","#### Função de Perda e Otimizador\n"," - A `Função de Perda` e o `Otimizador` são definidos na próxima célula.\n"," - A `Função de Perda` é usada para calcular a diferença na saída criada pelo modelo e a saída real.\n"," - O `Otimizador` é usado para atualizar os pesos da rede neural para melhorar seu desempenho.\n","\n","#### Leitura Adicional\n","- Você pode consultar meus [Tutoriais Pytorch](https://github.com/abhimishra91/pytorch-tutorials) para ter uma intuição sobre Função de Perda e Otimizador.\n","- [Documentação Pytorch para Função de Perda](https://pytorch.org/docs/stable/nn.html#loss-functions)\n","- [Documentação Pytorch para Otimizador](https://pytorch.org/docs/stable/optim.html)\n","- Consulte os links fornecidos no início do notebook para ler mais sobre o SciBERT.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HP5i4lLPGa3"},"outputs":[],"source":["# Criando o modelo personalizado, adicionando uma camada de dropout e uma camada densa em cima do SciBERT para obter a saída final do modelo.\n","\n","class SciBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(SciBERTClass, self).__init__()\n","        self.l1 = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"JWSaTZq0PGa3","outputId":"ffda907f-f448-4948-9ee0-e8c9df5410b7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712374081289,"user_tz":180,"elapsed":1294,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SciBERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=51, bias=True)\n",")"]},"metadata":{},"execution_count":213}],"source":["model = SciBERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXrJlTVBPGa4"},"outputs":[],"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"markdown","metadata":{"id":"0rZ-vDvxPGa4"},"source":["<a id='section05'></a>\n","### Ajuste Fino do Modelo\n","\n","Depois de todo o esforço de carregar e preparar os dados e conjuntos de dados, criar o modelo e definir sua função de perda e otimizador, esta é provavelmente a etapa mais fácil do processo.\n","\n","Aqui definimos uma função de treinamento que treina o modelo no conjunto de dados de treinamento criado acima, um número especificado de vezes (EPOCH). Um epoch define quantas vezes os dados completos serão passados pela rede.\n","\n","Os seguintes eventos acontecem nesta função para ajustar finamente a rede neural:\n","- O dataloader passa dados para o modelo com base no tamanho do lote (batch size).\n","- A saída subsequente do modelo e a categoria real são comparadas para calcular a perda.\n","- O valor da perda é usado para otimizar os pesos dos neurônios na rede.\n","- Após cada 5000 etapas, o valor da perda é impresso no console.\n","\n","Como você pode ver, em apenas 1 epoch, na etapa final, o modelo estava trabalhando com uma perda minúscula de 0.0002485, ou seja, a saída está extremamente próxima da saída real.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWboAMfkPGa4"},"outputs":[],"source":["# Function to calcuate the accuracy of the model\n","\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJ4ghzvrPGa4"},"outputs":[],"source":["# Defining the training function on the 80% of the dataset for tuning the distilbert model\n","\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","\n","        if _%5000==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples\n","            print(f\"Training Loss per 5000 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return"]},{"cell_type":"markdown","source":[],"metadata":{"id":"NnXUO6s0oR-Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wps1lx_jPGa4","outputId":"fd02cb82-1466-4e69-be29-92dcf971f603","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712374133974,"user_tz":180,"elapsed":44512,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 5000 steps: 3.9728643894195557\n","Training Accuracy per 5000 steps: 1.5625\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 0: 17.15481171548117\n","Training Loss Epoch: 3.7677578926086426\n","Training Accuracy Epoch: 17.15481171548117\n","Epoch 2/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 3.4879767894744873\n","Training Accuracy per 5000 steps: 26.5625\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 1: 30.96234309623431\n","Training Loss Epoch: 3.275606095790863\n","Training Accuracy Epoch: 30.96234309623431\n","Epoch 3/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 3.166917324066162\n","Training Accuracy per 5000 steps: 28.125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 2: 30.96234309623431\n","Training Loss Epoch: 3.032094657421112\n","Training Accuracy Epoch: 30.96234309623431\n","Epoch 4/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 2.8926842212677\n","Training Accuracy per 5000 steps: 31.25\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 3: 32.21757322175732\n","Training Loss Epoch: 2.8399935364723206\n","Training Accuracy Epoch: 32.21757322175732\n","Epoch 5/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 2.841787815093994\n","Training Accuracy per 5000 steps: 29.6875\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 4: 38.07531380753138\n","Training Loss Epoch: 2.6788305044174194\n","Training Accuracy Epoch: 38.07531380753138\n","Epoch 6/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 2.313256025314331\n","Training Accuracy per 5000 steps: 50.0\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 5: 43.51464435146443\n","Training Loss Epoch: 2.52232164144516\n","Training Accuracy Epoch: 43.51464435146443\n","Epoch 7/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 2.5963830947875977\n","Training Accuracy per 5000 steps: 40.625\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 6: 47.28033472803347\n","Training Loss Epoch: 2.367042362689972\n","Training Accuracy Epoch: 47.28033472803347\n","Epoch 8/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 2.1046783924102783\n","Training Accuracy per 5000 steps: 51.5625\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 7: 49.7907949790795\n","Training Loss Epoch: 2.227466106414795\n","Training Accuracy Epoch: 49.7907949790795\n","Epoch 9/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.8679133653640747\n","Training Accuracy per 5000 steps: 59.375\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 8: 55.23012552301255\n","Training Loss Epoch: 2.083028942346573\n","Training Accuracy Epoch: 55.23012552301255\n","Epoch 10/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.9727753400802612\n","Training Accuracy per 5000 steps: 60.9375\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 9: 59.8326359832636\n","Training Loss Epoch: 1.9488272964954376\n","Training Accuracy Epoch: 59.8326359832636\n","Epoch 11/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.7690180540084839\n","Training Accuracy per 5000 steps: 70.3125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 10: 64.43514644351464\n","Training Loss Epoch: 1.7912741005420685\n","Training Accuracy Epoch: 64.43514644351464\n","Epoch 12/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.5261508226394653\n","Training Accuracy per 5000 steps: 70.3125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 11: 69.0376569037657\n","Training Loss Epoch: 1.6706460416316986\n","Training Accuracy Epoch: 69.0376569037657\n","Epoch 13/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.4160088300704956\n","Training Accuracy per 5000 steps: 75.0\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 12: 74.47698744769875\n","Training Loss Epoch: 1.5312567055225372\n","Training Accuracy Epoch: 74.47698744769875\n","Epoch 14/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.3662394285202026\n","Training Accuracy per 5000 steps: 82.8125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 13: 74.05857740585775\n","Training Loss Epoch: 1.4233213067054749\n","Training Accuracy Epoch: 74.05857740585775\n","Epoch 15/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.2755343914031982\n","Training Accuracy per 5000 steps: 78.125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 14: 77.40585774058577\n","Training Loss Epoch: 1.324386179447174\n","Training Accuracy Epoch: 77.40585774058577\n","Epoch 16/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.2620563507080078\n","Training Accuracy per 5000 steps: 79.6875\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 15: 78.24267782426779\n","Training Loss Epoch: 1.242207646369934\n","Training Accuracy Epoch: 78.24267782426779\n","Epoch 17/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 0.9009363055229187\n","Training Accuracy per 5000 steps: 84.375\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 16: 79.9163179916318\n","Training Loss Epoch: 1.1331317275762558\n","Training Accuracy Epoch: 79.9163179916318\n","Epoch 18/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 0.8528594374656677\n","Training Accuracy per 5000 steps: 84.375\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 17: 79.4979079497908\n","Training Loss Epoch: 1.05393086373806\n","Training Accuracy Epoch: 79.4979079497908\n","Epoch 19/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 1.136946439743042\n","Training Accuracy per 5000 steps: 78.125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 18: 81.17154811715481\n","Training Loss Epoch: 0.9761831760406494\n","Training Accuracy Epoch: 81.17154811715481\n","Epoch 20/20\n","Número total de documentos: 239\n","Número total de documentos: 239\n","Training Loss per 5000 steps: 0.9351298213005066\n","Training Accuracy per 5000 steps: 82.8125\n","Número total de documentos: 239\n","The Total Accuracy for Epoch 19: 83.26359832635983\n","Training Loss Epoch: 0.9159723371267319\n","Training Accuracy Epoch: 83.26359832635983\n"]}],"source":["for epoch in range(EPOCHS):\n","    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n","    train(epoch)"]},{"cell_type":"markdown","metadata":{"id":"WBLi1-WtPGa5"},"source":["<a id='section06'></a>\n","### Validando o Modelo\n","\n","Durante a etapa de validação, passamos os dados não vistos (Conjunto de Dados de Teste) para o modelo. Esta etapa determina quão bem o modelo se sai nos dados não vistos.\n","\n","Estes dados não vistos são os 20% das publicacões que foram separadas durante a criação do Conjunto de Dados.\n","Durante a etapa de validação, os pesos do modelo não são atualizados. Apenas a saída final é comparada com o valor real. Essa comparação é então usada para calcular a precisão do modelo.\n","\n","Como você pode ver, o modelo está prevendo a classe correta do autor em questão com uma precisão de 82%.\n"]},{"cell_type":"code","source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0\n","    n_wrong = 0\n","    total = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","\n","            outputs = model(ids, mask).squeeze()\n","\n","            # Verificar as dimensões dos tensores de entrada e destino\n","            #if outputs.shape[0] != targets.shape[0]:\n","             #   print(\"Erro: Dimensões dos tensores de entrada e destino não correspondem. Ignorando...\")\n","              #  continue\n","\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","\n","            print(f\"Input tensor shape: {outputs.shape}\")\n","            print(f\"Target tensor shape: {targets.shape}\")\n","\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples += targets.size(0)\n","\n","            if _ % 5000 == 0:\n","                loss_step = tr_loss / nb_tr_steps\n","                accu_step = (n_correct * 100) / nb_tr_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","\n","    return epoch_accu\n","\n"],"metadata":{"id":"xXchtUkHFX4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kEdHCNpPGa5","outputId":"419decaf-396c-40a4-8fac-a1b066d42b72","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712374142294,"user_tz":180,"elapsed":620,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["This is the validation section to print the accuracy and see how it performs\n","Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n","Número total de documentos: 60\n","Número total de documentos: 60\n","Input tensor shape: torch.Size([32, 51])\n","Target tensor shape: torch.Size([32])\n","Validation Loss per 100 steps: 1.756794810295105\n","Validation Accuracy per 100 steps: 65.625\n","Número total de documentos: 60\n","Input tensor shape: torch.Size([28, 51])\n","Target tensor shape: torch.Size([28])\n","Validation Loss Epoch: 1.928013026714325\n","Validation Accuracy Epoch: 63.333333333333336\n","Accuracy on test data = 63.33%\n"]}],"source":["print('This is the validation section to print the accuracy and see how it performs')\n","print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n","\n","acc = valid(model, testing_loader)\n","print(\"Accuracy on test data = %0.2f%%\" % acc)"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","def valid(model, testing_loader):\n","    model.eval()\n","    all_predictions = []\n","    all_targets = []\n","    tr_loss = 0\n","\n","    num_classes = 16\n","\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","\n","            outputs = model(ids, mask).squeeze()\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_targets.extend(targets.cpu().numpy())\n","\n","    # Calculate the accuracy\n","    accuracy = np.mean(np.array(all_predictions) == np.array(all_targets)) * 100\n","\n","    # Print validation loss and accuracy\n","    epoch_loss = tr_loss / len(testing_loader)\n","    print(f\"Validation Loss: {epoch_loss}\")\n","    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n","\n","    # Plot histogram of document occurrence in classes\n","    plt.figure(figsize=(10, 6))\n","    plt.hist(all_targets, bins=np.arange(num_classes+1)-0.5, color='blue', edgecolor='black', align='mid')\n","    plt.xlabel(\"Classes\")\n","    plt.ylabel(\"Número de documentos\")\n","    plt.title(\"Ocorrência de documentos nas classes - Autor: \" + autor)\n","    plt.xticks(range(num_classes))\n","    plt.grid(axis='y', linestyle='--', alpha=0.7)\n","    plt.show()\n","\n","    # Plot other relevant graphs if needed\n","\n","    # Print classification report\n","    print(\"Relatórios de classificação:\")\n","    print(classification_report(all_targets, all_predictions))\n","\n","    return accuracy\n","\n","# Call the valid function after the training\n","print('Esta é a seção de validação para imprimir a acurácia e ver como está o desempenho')\n","print('Aqui estamos utilizando o carregador criado para o conjunto de dados de validação, a abordagem utiliza mais o PyTorch')\n","\n","\n","acc = valid(model, testing_loader)\n","print(\"Accuracy on test data = %0.2f%%\" % acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vo-lPlb7QO9C","executionInfo":{"status":"ok","timestamp":1712374145787,"user_tz":180,"elapsed":1213,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}},"outputId":"b0958e07-241f-4939-b40c-23da0708b863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Esta é a seção de validação para imprimir a acurácia e ver como está o desempenho\n","Aqui estamos utilizando o carregador criado para o conjunto de dados de validação, a abordagem utiliza mais o PyTorch\n","Número total de documentos: 60\n","Número total de documentos: 60\n","Número total de documentos: 60\n","Número total de documentos: 60\n","Validation Loss: 1.9044561982154846\n","Validation Accuracy: 63.33%\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Relatórios de classificação:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         5\n","           2       0.57      0.89      0.70         9\n","           3       0.00      0.00      0.00         1\n","           6       0.50      1.00      0.67         1\n","           7       0.00      0.00      0.00         1\n","           8       1.00      1.00      1.00         5\n","          10       1.00      1.00      1.00         1\n","          12       1.00      1.00      1.00         1\n","          15       0.00      0.00      0.00         1\n","          16       0.00      0.00      0.00         4\n","          17       0.50      0.82      0.62        11\n","          18       0.67      1.00      0.80         2\n","          19       0.00      0.00      0.00         1\n","          20       0.50      1.00      0.67         4\n","          22       0.00      0.00      0.00         1\n","          25       0.00      0.00      0.00         2\n","          28       0.50      1.00      0.67         1\n","          29       0.00      0.00      0.00         1\n","          30       1.00      1.00      1.00         1\n","          32       0.00      0.00      0.00         1\n","          33       0.00      0.00      0.00         1\n","          35       0.00      0.00      0.00         1\n","          36       0.00      0.00      0.00         1\n","          38       0.00      0.00      0.00         1\n","          42       0.00      0.00      0.00         1\n","          48       0.00      0.00      0.00         1\n","\n","    accuracy                           0.63        60\n","   macro avg       0.32      0.41      0.35        60\n","weighted avg       0.47      0.63      0.53        60\n","\n","Accuracy on test data = 63.33%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"O9VXudctPGa5"},"source":["<a id='section07'></a>\n","### Salvando os Artefatos do Modelo Treinado para Inferência\n","\n","Este é o último passo no processo de ajuste fino do modelo.\n","\n","O modelo e seu vocabulário são salvos localmente. Esses arquivos são então usados no futuro para fazer inferências sobre novas entradas de manchetes de notícias.\n","\n","Por favor, lembre-se de que uma rede neural treinada só é útil quando usada em inferência real após seu treinamento.\n","\n","No ciclo de vida de projetos de aprendizado de máquina, isso é apenas metade do trabalho feito. Deixaremos a inferência desses modelos para outro dia.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jX5GbHTPPGa5","outputId":"48d7095f-3b5c-4e61-c801-e940ae3b1287","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"error","timestamp":1712408827051,"user_tz":180,"elapsed":459,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}}},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 7) (<ipython-input-3-43be22e61e46>, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-43be22e61e46>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    output_dir = \"/content/drive/MyDrive/ADAN/fine_tuning_sci_bert/output/'\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 7)\n"]}],"source":["from google.colab import drive\n","\n","# Montar o Google Drive\n","drive.mount('/content/drive')\n","\n","# Definir o caminho para a pasta \"output\" no Google Drive\n","output_dir = \"/content/drive/MyDrive/ADAN/fine_tuning_sci_bert/output/'\n","\n","\n","# Salvar o modelo e o vocabulário na pasta \"output\"\n","output_model_file = output_dir + 'pytorch_distilbert_publicacoes.bin'\n","output_vocab_file = output_dir + 'vocab_distilbert_publicacoes.bin'\n","\n","model_to_save = model\n","torch.save(model_to_save, output_model_file)\n","tokenizer.save_vocabulary(output_vocab_file)\n","\n","print('All files saved in the \"output\" folder in Google Drive.')\n"]},{"cell_type":"markdown","source":["Previsão de Categoria de Artigo com SciBERT\n","\n","Este código realiza a previsão da categoria de um novo artigo utilizando um modelo SciBERT pré-treinado. Siga as instruções abaixo para executar o código:\n","\n","  - Carregar Tokenizador e Modelo Pré-Treinado:\n","    - Certifique-se de que os arquivos pytorch_scibert_news.bin e vocab_scibert_news.bin estejam na pasta correta. Caso contrário, ajuste o caminho dos arquivos no código. O tokenizador e o modelo serão carregados a partir dos arquivos salvos.\n","\n","  - Definir Dados de Entrada:\n","    - Substitua o texto \"Título do novo artigo\" e \"Resumo do novo artigo\" pelos títulos e resumos reais do seu novo artigo que deseja classificar.\n","\n","  - Tokenizar os Dados de Entrada:\n","    - O tokenizador será aplicado aos dados de entrada para prepará-los para a previsão.\n","\n","   - Realizar a Previsão:\n","    - O modelo pré-treinado será usado para fazer a previsão da categoria do novo artigo com base nos dados fornecidos.\n","  - Exibir os Resultados:\n","    - As probabilidades de pertencimento a cada classe serão exibidas, juntamente com a classe prevista com maior probabilidade.\n","\n","Observação: Certifique-se de ter montado o Google Drive e de ter acesso aos arquivos do modelo e do tokenizador no ambiente do Colab."],"metadata":{"id":"h92VFhWPfbXD"}},{"cell_type":"code","source":["from google.colab import drive\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# Montar o Google Drive\n","drive.mount('/content/drive')\n","\n","# Caminho para o modelo e o tokenizador na pasta output do Google Drive\n","output_model_file = '/content/drive/MyDrive/output/pytorch_scibert_publicacoes.bin'\n","output_vocab_file = '/content/drive/MyDrive/output/vocab_scibert_publicacoes.bin'\n","\n","# Carregar o tokenizador e o modelo salvos\n","tokenizer = AutoTokenizer.from_pretrained(output_vocab_file)\n","model = AutoModelForSequenceClassification.from_pretrained(output_model_file)\n","\n","# Definir os dados de entrada para a previsão\n","titulo = \"Título do novo artigo\"\n","abstract = \"Resumo do novo artigo\"\n","\n","# Tokenizar os dados de entrada\n","inputs = tokenizer(titulo, abstract, return_tensors='pt')\n","\n","# Fazer a previsão\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Obter as probabilidades para cada classe\n","probabilidades = torch.softmax(outputs.logits, dim=1).squeeze()\n","\n","# Obter a classe prevista com maior probabilidade\n","classe_prevista = torch.argmax(probabilidades).item()\n","\n","# Exibir os resultados\n","print(\"Probabilidades de classe:\", probabilidades)\n","print(\"Classe prevista:\", classe_prevista)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"kP8R-gnTgtp-","executionInfo":{"status":"error","timestamp":1712408800022,"user_tz":180,"elapsed":10748,"user":{"displayName":"Natan Rodrigues","userId":"00699204098925504974"}},"outputId":"c3facd13-d0b9-458e-932c-84bf3317af7b"},"execution_count":2,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f37e8cc2ce9e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Montar o Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Caminho para o modelo e o tokenizador na pasta output do Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1ToiNXuzyDnHVJTUF2VsHlDL8Za9dkOSw","timestamp":1712031339049},{"file_id":"https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb","timestamp":1711984658371}],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}